[package]
name = "burn-lm-inference"
authors = ["nathanielsimard <nathaniel.simard.42@gmail.com>"]
categories = []
description = "Burn Large Models Engine - Inference."
documentation = "https://docs.rs/burn-lm-inference"
repository = "https://github.com/tracel-ai/burn-lm"
rust-version = "1.88"

edition.workspace = true
version.workspace = true
license.workspace = true
readme.workspace = true

[features]
default = []
# default = ["legacy-v018"] # Necessary when building with burn-0.18

# Feature flag to deactivate the default backend.
selected-backend = []

# Feature to make burn-lm compile with burn 0.18.0
legacy-v018 = []

candle-accelerate = ["burn/candle", "burn/accelerate", "selected-backend"]
candle-cpu = ["burn/candle", "selected-backend"]
candle-cuda = ["burn/candle-cuda", "selected-backend"]
candle-metal = ["burn/candle", "burn/metal", "selected-backend"]

cuda = ["burn/cuda", "burn/default", "selected-backend"]
rocm = ["burn/rocm", "burn/default", "selected-backend"]
metal = ["burn/metal", "selected-backend"]
libtorch = ["burn/tch", "selected-backend"]
libtorch-cpu = ["burn/tch", "selected-backend"]
ndarray = ["burn/ndarray"]
ndarray-blas-accelerate = ["ndarray", "burn/accelerate"]
ndarray-blas-netlib = ["ndarray", "burn/blas-netlib"]
ndarray-blas-openblas = ["ndarray", "burn/openblas"]
wgpu = ["burn/wgpu", "burn/default", "selected-backend"]
vulkan = ["burn/vulkan", "burn/default", "selected-backend"]
wgpu-cpu = ["burn/wgpu", "burn/default", "selected-backend"]

f16 = []
bf16 = []
f32 = []

[dependencies]
burn = { workspace = true, default-features = false, features = ["ndarray"] }
burn-lm-macros = { path = "../burn-lm-macros", version = "0.0.1" }

cfg-if = { workspace = true }
clap = { workspace = true }
comfy-table = { workspace = true }
serde = { workspace = true }
serde_json = { workspace = true }
strum = { workspace = true }
thiserror = { workspace = true }
tracing = { workspace = true }
tracing-subscriber = { workspace = true }

[dev-dependencies]
rstest = { workspace = true }
